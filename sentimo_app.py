import streamlit as st
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from langdetect import detect_langs

# ì–¸ì–´ ê°ì§€ í•¨ìˆ˜ ê°œì„  (langdetect í™•ë¥  ê¸°ë°˜)
def detect_language(text):
    try:
        langs = detect_langs(text)
        if langs and langs[0].prob > 0.80:
            return langs[0].lang
        else:
            return "unknown"
    except:
        return "unknown"

# ëª¨ë¸ ë¡œë“œ
@st.cache_resource(show_spinner=False)
def load_models():
    # í•œêµ­ì–´ ê°ì • ë¶„ì„ ëª¨ë¸ êµì²´ (ê³µê°œ ê°€ëŠ¥ ëª¨ë¸)
    ko_tokenizer = AutoTokenizer.from_pretrained("beomi/KcELECTRA-base-v2022")
    ko_model = AutoModelForSequenceClassification.from_pretrained("beomi/KcELECTRA-base-v2022")

    # ì˜ì–´ ê°ì • ë¶„ì„ ëª¨ë¸
    en_tokenizer = AutoTokenizer.from_pretrained("j-hartmann/emotion-english-distilroberta-base")
    en_model = AutoModelForSequenceClassification.from_pretrained("j-hartmann/emotion-english-distilroberta-base")

    return (ko_tokenizer, ko_model), (en_tokenizer, en_model)

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ê°•ì¡° í‘œí˜„ ì •ì œ)
def preprocess_text(text):
    return text.replace("ë„ˆë¬´ë„ˆë¬´", "ë„ˆë¬´ ë„ˆë¬´").strip()

# ê°ì • ì˜ˆì¸¡ í•¨ìˆ˜
def predict_sentiment(text, ko_model_pack, en_model_pack):
    lang = detect_language(text)
    cleaned_text = preprocess_text(text)

    if lang == 'ko':
        tokenizer, model = ko_model_pack
        positive_label = 1
    elif lang == 'en':
        tokenizer, model = en_model_pack
        positive_emotions = ["joy", "love", "surprise"]
        negative_emotions = [
            "anger", "sadness", "fear", "disgust", "disappointment", "remorse",
            "grief", "disapproval", "embarrassment", "annoyance", "nervousness"
        ]
    else:
        return "ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨", 0.0, lang

    inputs = tokenizer(cleaned_text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = F.softmax(logits, dim=1).numpy()[0]

    if lang == 'ko':
        result = "ê¸ì •" if probs[positive_label] > probs[1 - positive_label] else "ë¶€ì •"
        confidence = abs(probs[positive_label] - probs[1 - positive_label])  # í™•ì‹ ë„ ê°œì„  ì•„ì´ë””ì–´ 1 ì ìš©
    else:
        # ëª¨ë¸ì´ ì¶œë ¥í•˜ëŠ” í´ë˜ìŠ¤ ìˆ˜ì— ë”°ë¼ labels ì˜ë¼ì„œ ì‚¬ìš©
        labels = [
            "admiration", "amusement", "anger", "annoyance", "approval", "caring", "confusion",
            "curiosity", "desire", "disappointment", "disapproval", "disgust", "embarrassment",
            "excitement", "fear", "gratitude", "grief", "joy", "love", "nervousness", "optimism",
            "pride", "realization", "relief", "remorse", "sadness", "surprise"
        ]
        labels = labels[:len(probs)]  # ëª¨ë¸ ì¶œë ¥ í¬ê¸°ì— ë§ì¶° ìë¥´ê¸°
        emotion_scores = {labels[i]: probs[i] for i in range(len(labels))}
        pos_score = sum([emotion_scores[e] for e in positive_emotions if e in emotion_scores])
        neg_score = sum([emotion_scores[e] for e in negative_emotions if e in emotion_scores])
        result = "ê¸ì •" if pos_score >= neg_score else "ë¶€ì •"
        confidence = abs(pos_score - neg_score)  # í™•ì‹ ë„ ê°œì„  ì•„ì´ë””ì–´ 1 ì ìš©

    return result, confidence, lang

# Streamlit UI
st.set_page_config(page_title="Sentimo ê°ì • ë¶„ì„", layout="centered")
st.title("ğŸ§  Sentimo: ì‹¤ì‹œê°„ ê°ì • ë¶„ì„")
st.write("ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ í•œêµ­ì–´/ì˜ì–´ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")

# ìºì‹œ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë”©
st.cache_resource.clear()
ko_model_pack, en_model_pack = load_models()

# ì…ë ¥ ì¸í„°í˜ì´ìŠ¤
user_input = st.text_area("âœï¸ ê°ì •ì„ ì•Œê³  ì‹¶ì€ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:", height=100)

if user_input:
    result, confidence, lang = predict_sentiment(user_input, ko_model_pack, en_model_pack)

    st.markdown(f"**ğŸ” ê°ì§€ëœ ì–¸ì–´:** `{lang}`")
    st.markdown(f"**ğŸ“Š ë¶„ì„ ê²°ê³¼:** `{result}`")
    st.markdown(f"**ğŸ“ˆ í™•ì‹ ë„:** `{confidence:.2%}`")
